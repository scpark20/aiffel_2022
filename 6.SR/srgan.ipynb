{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34a07137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "train, valid = tfds.load(\n",
    "    \"div2k/bicubic_x4\", \n",
    "    split=[\"train\",\"validation\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "def preprocessing(lr, hr):\n",
    "    hr = tf.cast(hr, tf.float32) /255.\n",
    "        \n",
    "    # 이미지의 크기가 크므로 (96,96,3) 크기로 임의 영역을 잘라내어 사용합니다.\n",
    "    hr_patch = tf.image.random_crop(hr, size=[96,96,3])\n",
    "        \n",
    "    # 잘라낸 고해상도 이미지의 가로, 세로 픽셀 수를 1/4배로 줄입니다\n",
    "    # 이렇게 만든 저해상도 이미지를 SRGAN의 입력으로 사용합니다.\n",
    "    lr_patch = tf.image.resize(hr_patch, [96//4, 96//4], \"bicubic\")\n",
    "    return lr_patch, hr_patch\n",
    "\n",
    "train = train.map(preprocessing).shuffle(buffer_size=10).repeat().batch(8)\n",
    "valid = valid.map(preprocessing).repeat().batch(8)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a27855b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import Input, Model, layers\n",
    "\n",
    "# 그림의 파란색 블록을 정의합니다.\n",
    "def gene_base_block(x):\n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(x)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.PReLU(shared_axes=[1,2])(out)\n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    return layers.Add()([x, out])\n",
    "\n",
    "# 그림의 뒤쪽 연두색 블록을 정의합니다.\n",
    "def upsample_block(x):\n",
    "    out = layers.Conv2D(256, 3, 1, \"same\")(x)\n",
    "    # 그림의 PixelShuffler 라고 쓰여진 부분을 아래와 같이 구현합니다.\n",
    "    out = layers.Lambda(lambda x: tf.nn.depth_to_space(x, 2))(out)\n",
    "    return layers.PReLU(shared_axes=[1,2])(out)\n",
    "    \n",
    "# 전체 Generator를 정의합니다.\n",
    "def get_generator(input_shape=(None, None, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    out = layers.Conv2D(64, 9, 1, \"same\")(inputs)\n",
    "    out = residual = layers.PReLU(shared_axes=[1,2])(out)\n",
    "    \n",
    "    for _ in range(5):\n",
    "        out = gene_base_block(out)\n",
    "    \n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.Add()([residual, out])\n",
    "    \n",
    "    for _ in range(2):\n",
    "        out = upsample_block(out)\n",
    "        \n",
    "    out = layers.Conv2D(3, 9, 1, \"same\", activation=\"tanh\")(out)\n",
    "    return Model(inputs, out)\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51d2a000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅\n"
     ]
    }
   ],
   "source": [
    "# 그림의 파란색 블록을 정의합니다.\n",
    "def disc_base_block(x, n_filters=128):\n",
    "    out = layers.Conv2D(n_filters, 3, 1, \"same\")(x)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    out = layers.Conv2D(n_filters, 3, 2, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    return layers.LeakyReLU()(out)\n",
    "\n",
    "# 전체 Discriminator 정의합니다.\n",
    "def get_discriminator(input_shape=(None, None, 3)):\n",
    "    inputs = Input(input_shape)\n",
    "    \n",
    "    out = layers.Conv2D(64, 3, 1, \"same\")(inputs)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    out = layers.Conv2D(64, 3, 2, \"same\")(out)\n",
    "    out = layers.BatchNormalization()(out)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    \n",
    "    for n_filters in [128, 256, 512]:\n",
    "        out = disc_base_block(out, n_filters)\n",
    "    \n",
    "    out = layers.Dense(1024)(out)\n",
    "    out = layers.LeakyReLU()(out)\n",
    "    out = layers.Dense(1, activation=\"sigmoid\")(out)\n",
    "    return Model(inputs, out)\n",
    "\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64103b8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import losses, metrics, optimizers\n",
    "\n",
    "generator = get_generator()\n",
    "discriminator = get_discriminator()\n",
    "\n",
    "# 사용할 loss function 및 optimizer 를 정의합니다.\n",
    "bce = losses.BinaryCrossentropy(from_logits=False)\n",
    "mse = losses.MeanSquaredError()\n",
    "gene_opt = optimizers.Adam()\n",
    "disc_opt = optimizers.Adam()\n",
    "\n",
    "def get_gene_loss(fake_out):\n",
    "    return bce(tf.ones_like(fake_out), fake_out)\n",
    "\n",
    "def get_disc_loss(real_out, fake_out):\n",
    "    return bce(tf.ones_like(real_out), real_out) + bce(tf.zeros_like(fake_out), fake_out)\n",
    "\n",
    "@tf.function\n",
    "def get_content_loss(hr_real, hr_fake):\n",
    "    return mse(hr_real, hr_fake)\n",
    "\n",
    "@tf.function\n",
    "def step(lr, hr_real):\n",
    "    with tf.GradientTape() as gene_tape, tf.GradientTape() as disc_tape:\n",
    "        hr_fake = generator(lr, training=True)\n",
    "        \n",
    "        real_out = discriminator(hr_real, training=True)\n",
    "        fake_out = discriminator(hr_fake, training=True)\n",
    "        \n",
    "        perceptual_loss = get_content_loss(hr_real, hr_fake) + 1e-3 * get_gene_loss(fake_out)\n",
    "        discriminator_loss = get_disc_loss(real_out, fake_out)\n",
    "        \n",
    "    gene_gradient = gene_tape.gradient(perceptual_loss, generator.trainable_variables)\n",
    "    disc_gradient = disc_tape.gradient(discriminator_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    gene_opt.apply_gradients(zip(gene_gradient, generator.trainable_variables))\n",
    "    disc_opt.apply_gradients(zip(disc_gradient, discriminator.trainable_variables))\n",
    "    return perceptual_loss, discriminator_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f9bf33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "gene_losses = metrics.Mean()\n",
    "disc_losses = metrics.Mean()\n",
    "\n",
    "for epoch in range(1, 10):\n",
    "    for i, (lr, hr) in enumerate(train):\n",
    "        g_loss, d_loss = step(lr, hr)\n",
    "        \n",
    "        gene_losses.update_state(g_loss)\n",
    "        disc_losses.update_state(d_loss)\n",
    "        \n",
    "        # 10회 반복마다 loss를 출력합니다.\n",
    "        if (i+1) % 10 == 0:\n",
    "            print(f\"EPOCH[{epoch}] - STEP[{i+1}] \\nGenerator_loss:{gene_losses.result():.4f} \\nDiscriminator_loss:{disc_losses.result():.4f}\", end=\"\\n\\n\")\n",
    "             \n",
    "    gene_losses.reset_states()\n",
    "    disc_losses.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933b13f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "\n",
    "def apply_srgan(image):\n",
    "    image = tf.cast(image[np.newaxis, ...], tf.float32)\n",
    "    sr = generator.predict(image/255)\n",
    "    sr = sr * 255\n",
    "    sr = tf.clip_by_value(sr, 0, 255)\n",
    "    sr = tf.round(sr)\n",
    "    sr = tf.cast(sr, tf.uint8)\n",
    "    return np.array(sr)[0]\n",
    "\n",
    "_, valid = tfds.load(\n",
    "    \"div2k/bicubic_x4\", \n",
    "    split=[\"train\", \"validation\"],\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "for i, (lr, hr) in enumerate(valid):\n",
    "    if i == 6: break\n",
    "\n",
    "srgan_hr = apply_srgan(lr)\n",
    "print(\"✅\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89136dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이미지의 특정 부분을 잘라내는 함수를 정의합니다.\n",
    "def crop(image, left_top, x=200, y=200):\n",
    "    return image[left_top[0]:(left_top[0]+x), left_top[1]:(left_top[1]+y), :]\n",
    "\n",
    "hr, lr = np.array(hr), np.array(lr)\n",
    "bicubic_hr = cv2.resize(\n",
    "    lr, \n",
    "    dsize=(hr.shape[1], hr.shape[0]), # 고해상도 이미지 크기로 설정\n",
    "    interpolation=cv2.INTER_CUBIC # bicubic 설정\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee69687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 자세히 시각화 하기 위해 3개 영역을 잘라냅니다.\n",
    "# 아래는 잘라낸 부분의 좌상단 좌표 3개 입니다.\n",
    "left_tops = [(400,500), (300,1200), (0,1000)]\n",
    "\n",
    "images = []\n",
    "for left_top in left_tops:\n",
    "    img1 = crop(bicubic_hr, left_top, 200, 200)\n",
    "    img2 = crop(srgan_hr , left_top, 200, 200)\n",
    "    img3 = crop(hr, left_top, 200, 200)\n",
    "    images.extend([img1, img2, img3])\n",
    "\n",
    "labels = [\"Bicubic\", \"SRGAN\", \"HR\"] * 3\n",
    "\n",
    "plt.figure(figsize=(18,18))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1) \n",
    "    plt.imshow(images[i])\n",
    "    plt.title(labels[i], fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bf1842d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8efb93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947cf979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497cc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
